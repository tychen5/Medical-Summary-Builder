from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Optional

from langchain.tools.retriever import create_retriever_tool
from langchain_core.documents import Document

from ..agents import create_react_agent
from ..config import settings
from ..data_ingestion import DocumentConverter, PDFMedicalLoader, TemplateLoader
from ..logging_config import configure_logging
from ..preprocessing import DocumentChunker, MetadataRouter, PageRelevanceRanker
from ..schemas import ClaimantProfile, MedicalSummary
from ..utils import ensure_directory
from ..vectorstore import VectorIndexManager
from ..llm import EmbeddingFactory, LLMClientFactory


@dataclass
class PipelineArtifacts:
    """Handles intermediate artefacts generated by the pipeline."""

    raw_pages: list[Document]
    chunk_paths: list[Path]
    vector_index_name: str


class MedicalSummaryPipeline:
    """High-level orchestration of the medical summary generation workflow."""

    def __init__(self) -> None:
        self.llm = LLMClientFactory.create()
        self.embedding_model = EmbeddingFactory.create()
        self.chunker = DocumentChunker(settings.chunk_size, settings.chunk_overlap)
        self.metadata_router = MetadataRouter(self.llm)
        self.page_ranker = PageRelevanceRanker(self.llm)
        self.vector_index_manager = VectorIndexManager(self.embedding_model)

    def setup(self) -> None:
        configure_logging()
        ensure_directory(settings.outputs_dir)
        ensure_directory(settings.reports_dir)
        ensure_directory(settings.diagnostics_dir)

    def ingest_source(self, pdf_path: Path | str) -> list[Document]:
        loader = PDFMedicalLoader(pdf_path)
        return loader.load()

    def convert_template(self, template_path: Path | str) -> Path:
        template = TemplateLoader(template_path).load()
        markdown_path = settings.cache_dir / "templates" / "medical_summary.md"
        ensure_directory(markdown_path.parent)
        markdown_path.write_text("\n".join(paragraph.text for paragraph in template.paragraphs), encoding="utf-8")
        return markdown_path

    def build_vector_index(self, documents: list[Document]) -> None:
        chunked_documents = self.chunker.split(documents)
        langchain_documents = [
            Document(page_content=chunk.text, metadata=chunk.metadata)
            for chunk in chunked_documents
        ]
        self.vector_index_manager.upsert(langchain_documents)

    def run(
        self,
        *,
        pdf_path: Path | str,
        template_path: Path | str,
        custom_instruction: Optional[str] = None,
        skip_indexing: bool = False,
    ) -> MedicalSummary:
        self.setup()
        if not skip_indexing:
            documents = self.ingest_source(pdf_path)
            self.build_vector_index(documents)
        self.convert_template(template_path)

        retriever = self.vector_index_manager.as_retriever()
        retriever_tool = create_retriever_tool(
            retriever,
            "medical_record_search",
            "Searches and returns information from the claimant's medical records.",
        )

        # Step 1: Run a ReAct agent to retrieve relevant information and generate a summary.
        summary_agent = create_react_agent(
            tools=[retriever_tool],
            system_prompt="You are an expert at extracting information from medical records. "
            "First, find all available details for the claimant profile. "
            "Then, provide a comprehensive summary of the findings.",
        )

        agent_input = {"messages": [("user", "Find and summarize all available claimant profile details.")]}
        summary_result = summary_agent.invoke(agent_input)

        # Extract the summary text from the agent's final message.
        summary_text = ""
        if messages := summary_result.get("messages"):
            if isinstance(messages, list) and messages:
                summary_text = messages[-1].content

        claimant_profile = ClaimantProfile()
        if summary_text:
            # Step 2: Use an LLM with structured output to parse the summary into the ClaimantProfile schema.
            structured_llm = self.llm.with_structured_output(ClaimantProfile)

            prompt = (
                "Given the following summary of a claimant's profile, "
                "extract the information into the ClaimantProfile format.\n\n"
                f"Summary:\n{summary_text}"
            )

            extracted_data = structured_llm.invoke(prompt)
            if isinstance(extracted_data, ClaimantProfile):
                claimant_profile = extracted_data

        # Further steps: agent-driven table filling, report generation
        return MedicalSummary(claimant_profile=claimant_profile)

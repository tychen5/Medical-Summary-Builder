from __future__ import annotations

import logging
import json
import datetime
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Iterable, Optional

from langchain.tools.retriever import create_retriever_tool
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage
from pydantic import BaseModel, Field, ValidationError

from ..agents import create_react_agent
from ..config import settings
from ..data_ingestion import DocumentConverter, PDFMedicalLoader, TemplateLoader
from ..logging_config import configure_logging
from ..preprocessing import DocumentChunker, MetadataRouter, PageRelevanceRanker
from ..schemas import ClaimantProfile, MedicalEvent, MedicalSummary
from ..utils import ensure_directory
from ..vectorstore import VectorIndexManager
from ..llm import EmbeddingFactory, LLMClientFactory


logger = logging.getLogger(__name__)


class AgentSummary(BaseModel):
    profile: ClaimantProfile = Field(default_factory=ClaimantProfile)
    events: list[MedicalEvent] = Field(default_factory=list)
    custom_tables: dict[str, list[dict[str, str]]] = Field(default_factory=dict)


@dataclass
class PipelineArtifacts:
    """Handles intermediate artefacts generated by the pipeline."""

    raw_pages: list[Document]
    chunk_paths: list[Path]
    vector_index_name: str


class MedicalSummaryPipeline:
    """High-level orchestration of the medical summary generation workflow."""

    def __init__(self) -> None:
        self.llm = LLMClientFactory.create(provider="openai")
        self.embedding_model = EmbeddingFactory.create()
        self.chunker = DocumentChunker(settings.chunk_size, settings.chunk_overlap)
        self.metadata_router = MetadataRouter(self.llm)
        self.page_ranker = PageRelevanceRanker(self.llm)
        self.vector_index_manager = VectorIndexManager(self.embedding_model)

    def setup(self) -> None:
        configure_logging()
        ensure_directory(settings.outputs_dir)
        ensure_directory(settings.reports_dir)
        ensure_directory(settings.diagnostics_dir)

    def ingest_source(self, pdf_path: Path | str) -> list[Document]:
        loader = PDFMedicalLoader(pdf_path)
        return loader.load()

    def convert_template(self, template_path: Path | str) -> Path:
        template = TemplateLoader(template_path).load()
        markdown_path = settings.cache_dir / "templates" / "medical_summary.md"
        ensure_directory(markdown_path.parent)
        markdown_path.write_text("\n".join(paragraph.text for paragraph in template.paragraphs), encoding="utf-8")
        return markdown_path

    def build_vector_index(self, documents: list[Document]) -> None:
        chunked_documents = self.chunker.split(documents)
        langchain_documents = [
            Document(page_content=chunk.text, metadata=chunk.metadata)
            for chunk in chunked_documents
        ]
        self.vector_index_manager.upsert(langchain_documents)

    def run(
        self,
        *,
        pdf_path: Path | str,
        template_path: Path | str,
        custom_instruction: Optional[str] = None,
        skip_indexing: bool = False,
    ) -> MedicalSummary:
        self.setup()
        if not skip_indexing:
            documents = self.ingest_source(pdf_path)
            self.build_vector_index(documents)
        self.convert_template(template_path)

        retriever = self.vector_index_manager.as_retriever()
        retriever_tool = create_retriever_tool(
            retriever,
            "medical_record_search",
            "Searches and returns information from the claimant's medical records.",
        )

        # Step 1: Run a ReAct agent to retrieve relevant information and generate a summary.
        agent_system_prompt = (
            "You are an expert at extracting information from medical records. "
            "First, use the supplied tool to gather authoritative evidence. "
            "Populate every claimant profile field (name, SSN, DOB, AOD, DLI, Age, Education, Title, Notes). "
            "Then construct a timeline of medical events with Date, Provider, Reason, and Reference (page label such as Pg 12/504). "
            "After gathering all evidence, produce a JSON object with the following shape: {\n"
            "  \"profile\": ClaimantProfile fields (claimant_name, ssn, date_of_birth, alleged_onset_date, date_last_insured, "
            "age_at_aod, current_age, education, title, notes),\n"
            "  \"events\": list of medical events with keys date (MM/DD/YYYY), provider, reason, reference (e.g., Pg 12/504),\n"
            "  \"custom_tables\": mapping of table names to lists of row dictionaries.\n"
            "}\n"
            "Cite the exact page numbers in the reference column. "
            "Ensure that every field is populated with the best available evidence or null if truly unavailable."
        )

        summary_agent = create_react_agent(
            tools=[retriever_tool],
            system_prompt=agent_system_prompt,
            provider="openai",
        )

        user_instruction_lines = [
            "Use the medical_record_search tool iteratively to gather all necessary facts before producing the final summary.",
        ]
        if custom_instruction:
            user_instruction_lines.append(
                f"{custom_instruction}"
            )

        agent_input = {"messages": [("user", "\n\n".join(user_instruction_lines))]}
        summary_result = summary_agent.invoke(agent_input)

        logger.debug("Agent summary_result: %s", summary_result)

        agent_summary = self._parse_agent_result(summary_result)

        if not agent_summary:
            logger.warning("Agent did not return structured data; attempting fallback extraction.")
            agent_summary = self._fallback_extraction(retriever, custom_instruction)

        if not agent_summary:
            logger.error("Fallback extraction failed; returning empty medical summary.")
            return MedicalSummary()

        return MedicalSummary(
            profile=agent_summary.profile,
            events=agent_summary.events,
            custom_tables=agent_summary.custom_tables,
        )

    def _parse_agent_result(self, result: dict[str, Any]) -> AgentSummary | None:
        """Normalize agent output (messages/return_values) into an AgentSummary instance."""
        if not isinstance(result, dict):
            return None

        # Path 1: LangGraph with `response_format` provides `structured_response`
        structured_response = result.get("structured_response")
        if isinstance(structured_response, AgentSummary):
            return structured_response
        if isinstance(structured_response, BaseModel):
            try:
                return AgentSummary.model_validate(
                    self._normalize_agent_payload(structured_response.model_dump())
                )
            except ValidationError as exc:
                logger.debug("Validation error on BaseModel structured_response: %s", exc)
        if isinstance(structured_response, dict):
            try:
                return AgentSummary.model_validate(self._normalize_agent_payload(structured_response))
            except ValidationError as exc:
                logger.debug("Validation error on 'structured_response': %s", exc)

        # Path 2: Older agent patterns might use `return_values`
        return_values = result.get("return_values")
        if isinstance(return_values, dict) and "output" in return_values:
            candidate = return_values["output"]
            if isinstance(candidate, AgentSummary):
                return candidate
            if isinstance(candidate, dict):
                try:
                    return AgentSummary.model_validate(self._normalize_agent_payload(candidate))
                except ValidationError as exc:
                    logger.debug("Validation error on dict from 'return_values': %s", exc)
            if isinstance(candidate, str):
                parsed = self._parse_json_string(candidate)
                if parsed:
                    return parsed

        # Path 3: Fallback to parsing the final message content
        messages = result.get("messages")
        if isinstance(messages, list) and messages:
            last_message = messages[-1]
            content = getattr(last_message, "content", None)

            for candidate_text in self._content_text_candidates(content):
                parsed = self._parse_json_string(candidate_text)
                if parsed:
                    return parsed

            if isinstance(content, dict):
                try:
                    return AgentSummary.model_validate(self._normalize_agent_payload(content))
                except (ValidationError, TypeError) as exc:
                    logger.debug("Failed to validate dict content from last message: %s", exc)

        return None

    def _parse_json_string(self, text: str) -> AgentSummary | None:
        if not text:
            return None

        candidates = self._json_candidates(text)
        for candidate in candidates:
            try:
                data = json.loads(candidate)
            except json.JSONDecodeError:
                continue

            normalized = self._normalize_agent_payload(data)
            try:
                return AgentSummary.model_validate(normalized)
            except ValidationError as exc:
                logger.debug("Validation error on JSON candidate: %s", exc)
                continue

        return None

    def _fallback_extraction(
        self,
        retriever,
        custom_instruction: Optional[str],
    ) -> AgentSummary | None:
        """Best-effort structured extraction using retrieved context and the base LLM."""

        context = self._collect_retrieved_context(
            retriever,
            queries=[
                "claimant profile information",
                "medical summary claimant details",
                "background claimant metadata",
                "timeline of medical events",
            ],
            max_chunks=12,
        )

        if not context:
            logger.warning("No context retrieved during fallback extraction.")
            return None

        prompt_parts = [
            "You are given excerpts from a medical case file.",
            "Fill in the claimant profile (name, SSN, DOB, AOD, DLI, age details, education, title, notes).",
            "Construct a timeline of significant medical events with date (MM/DD/YYYY), provider, reason, and reference page label (e.g., Pg 12/504).",
            "Return JSON with keys 'profile', 'events', and 'custom_tables'.",
            "The 'profile' object must include claimant_name, ssn, date_of_birth, alleged_onset_date, date_last_insured, age_at_aod, current_age, education, title, notes.",
            "The 'events' array must contain objects with keys date, provider, reason, reference.",
            "The 'custom_tables' object should map table names to arrays of row dictionaries (use an empty object if none).",
            "Context:",
            context,
        ]

        if custom_instruction:
            prompt_parts.append("Custom table guidance:\n" + custom_instruction)

        prompt = "\n\n".join(prompt_parts)

        try:
            response = self.llm.invoke(prompt)
        except Exception as exc:
            logger.error("Fallback extraction LLM call failed: %s", exc)
            return None

        response_text = getattr(response, "content", None)
        if isinstance(response_text, list):
            response_text = "".join(str(part) for part in response_text)

        if not response_text and hasattr(response, "text"):
            response_text = response.text

        if not response_text and isinstance(response, str):
            response_text = response

        if not response_text:
            logger.warning("Fallback extraction returned empty response.")
            return None

        
        parsed = self._parse_json_string(response_text)
        if not parsed:
            logger.warning("Fallback extraction could not parse JSON output.")
            logger.debug("Fallback extraction raw response: %s", response_text)
            return None

        return parsed

    @staticmethod
    def _coerce_date(value: Any) -> datetime.date | None | str:
        if isinstance(value, datetime.date):
            return value

        if value is None:
            return None

        if isinstance(value, str):
            stripped = value.strip()
            if not stripped:
                return None

            for fmt in ("%Y-%m-%d", "%m/%d/%Y", "%m/%d/%y"):
                try:
                    return datetime.datetime.strptime(stripped, fmt).date()
                except ValueError:
                    continue

        return value

    def _normalize_agent_payload(self, data: Any) -> Any:
        if not isinstance(data, dict):
            if isinstance(data, BaseModel):
                return self._normalize_agent_payload(data.model_dump())
            return data

        profile = data.get("profile")
        if isinstance(profile, dict):
            for field in (
                "date_of_birth",
                "alleged_onset_date",
                "date_last_insured",
            ):
                coerced = self._coerce_date(profile.get(field))
                if isinstance(coerced, datetime.date):
                    profile[field] = coerced
                elif coerced is None:
                    profile[field] = None
                else:
                    profile[field] = coerced

            data["profile"] = profile

        events = data.get("events")
        if isinstance(events, list):
            for event in events:
                if isinstance(event, dict):
                    coerced = self._coerce_date(event.get("date"))
                    if isinstance(coerced, datetime.date):
                        event["date"] = coerced
                    elif coerced is None:
                        event["date"] = None
                    else:
                        event["date"] = coerced

        return data

    def _json_candidates(self, text: str) -> list[str]:
        if not text:
            return []

        stripped = text.strip()
        candidates: list[str] = []

        def strip_code_fence(value: str) -> str:
            lines = value.strip().splitlines()
            if lines and lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            return "\n".join(lines).strip()

        fence_stripped = strip_code_fence(stripped)
        for candidate in {stripped, fence_stripped}:
            if candidate:
                candidates.append(candidate)

        candidates.extend(self._balanced_json_substrings(fence_stripped))
        return [cand for cand in candidates if cand]

    @staticmethod
    def _balanced_json_substrings(text: str) -> list[str]:
        substrings: list[str] = []
        if not text:
            return substrings

    def _content_text_candidates(self, content: Any) -> list[str]:
        candidates: list[str] = []

        def _collect(value: Any) -> None:
            if value is None:
                return
            if isinstance(value, str):
                stripped = value.strip()
                if stripped:
                    candidates.append(stripped)
            elif isinstance(value, BaseModel):
                candidates.append(json.dumps(value.model_dump()))
            elif isinstance(value, dict):
                for key in ("output", "text", "value", "content"):
                    maybe = value.get(key)
                    if isinstance(maybe, str) and maybe.strip():
                        candidates.append(maybe.strip())
                try:
                    candidates.append(json.dumps(value))
                except (TypeError, ValueError):
                    pass
            elif isinstance(value, (list, tuple)):
                for item in value:
                    _collect(item)
            elif isinstance(value, BaseMessage):
                _collect(getattr(value, "content", None))

        _collect(content)
        return candidates

        for opening, closing in (("{", "}"), ("[", "]")):
            stack: list[int] = []
            start_index: Optional[int] = None

            for idx, char in enumerate(text):
                if char == opening:
                    if not stack:
                        start_index = idx
                    stack.append(idx)
                elif char == closing and stack:
                    stack.pop()
                    if not stack and start_index is not None:
                        substrings.append(text[start_index : idx + 1])
                        start_index = None

        return substrings

    def _collect_retrieved_context(
        self,
        retriever,
        queries: Iterable[str],
        *,
        max_chunks: int = 10,
    ) -> str:
        """Aggregate top documents from the retriever into a single text context."""

        collected: list[str] = []
        seen_ids: set[str] = set()

        for query in queries:
            try:
                documents = retriever.invoke(query)
            except Exception as exc:
                logger.debug("Retriever invoke failed for query '%s': %s", query, exc)
                documents = []

            for doc in documents:
                if len(collected) >= max_chunks:
                    break

                doc_id = str(doc.metadata.get("id") or doc.metadata.get("page_number") or hash(doc.page_content))
                if doc_id in seen_ids:
                    continue

                seen_ids.add(doc_id)
                snippet = doc.page_content.strip()
                if snippet:
                    collected.append(
                        f"[Source: {doc.metadata.get('source', 'unknown')} | Page: {doc.metadata.get('page_label', 'n/a')}]\n{snippet}"
                    )

            if len(collected) >= max_chunks:
                break

        return "\n\n".join(collected)
